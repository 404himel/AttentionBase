{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df1edef-48d1-43ef-8da3-4b519676503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-20.0.0.tar.gz (3.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /home/himel/Desktop/venv/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/himel/Desktop/venv/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-20.0.0-cp312-cp312-linux_x86_64.whl size=4158259 sha256=40f7d4373f34febedb1ce003ed73f1a3c6578198f695e78ee8385a19ccd4babf\n",
      "  Stored in directory: /home/himel/.cache/pip/wheels/35/bc/f4/3551aa7a295bf59b6cbf9cb588197b668052e5ec92a02aff7f\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-20.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dlib opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e42c32-ebad-4171-9198-0d530ac0e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import math\n",
    "\n",
    "# Load the pre-trained facial landmark predictor model\n",
    "predictor_path = '/home/himel/Downloads/shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Eye aspect ratio calculation\n",
    "def eye_aspect_ratio(eye):\n",
    "    # Calculate the Euclidean distances between the two sets of vertical eye landmarks\n",
    "    A = math.sqrt((eye[1].x - eye[5].x)**2 + (eye[1].y - eye[5].y)**2)\n",
    "    B = math.sqrt((eye[2].x - eye[4].x)**2 + (eye[2].y - eye[4].y)**2)\n",
    "    \n",
    "    # Calculate the Euclidean distance between the horizontal eye landmarks\n",
    "    C = math.sqrt((eye[0].x - eye[3].x)**2 + (eye[0].y - eye[3].y)**2)\n",
    "    \n",
    "    # Return the Eye Aspect Ratio (EAR)\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Mouth aspect ratio calculation\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    # Calculate the distances between key landmarks on the mouth\n",
    "    A = math.sqrt((mouth[2].x - mouth[10].x)**2 + (mouth[2].y - mouth[10].y)**2)\n",
    "    B = math.sqrt((mouth[4].x - mouth[8].x)**2 + (mouth[4].y - mouth[8].y)**2)\n",
    "    \n",
    "    # Calculate the horizontal distance between the mouth\n",
    "    C = math.sqrt((mouth[0].x - mouth[6].x)**2 + (mouth[0].y - mouth[6].y)**2)\n",
    "    \n",
    "    # Return the Mouth Aspect Ratio (MAR)\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the frame\n",
    "    faces = detector(gray)\n",
    "\n",
    "    # Loop through each detected face\n",
    "    for face in faces:\n",
    "        # Get the landmarks for the face\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Get the coordinates for the eye landmarks (left and right eyes)\n",
    "        left_eye = [landmarks.part(i) for i in range(36, 42)]  # Left eye landmarks\n",
    "        right_eye = [landmarks.part(i) for i in range(42, 48)]  # Right eye landmarks\n",
    "        \n",
    "        # Get the coordinates for the mouth landmarks\n",
    "        mouth = [landmarks.part(i) for i in range(48, 68)]  # Mouth landmarks\n",
    "\n",
    "        # Calculate EAR for both eyes\n",
    "        left_eye_ear = eye_aspect_ratio(left_eye)\n",
    "        right_eye_ear = eye_aspect_ratio(right_eye)\n",
    "\n",
    "        # Calculate the average EAR\n",
    "        eye_ear = (left_eye_ear + right_eye_ear) / 2.0\n",
    "\n",
    "        # Calculate MAR for mouth\n",
    "        mouth_mar = mouth_aspect_ratio(mouth)\n",
    "\n",
    "        # Draw the landmarks and display EAR and MAR\n",
    "        for n in range(36, 42):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)  # Left Eye landmarks in green\n",
    "\n",
    "        for n in range(42, 48):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)  # Right Eye landmarks in green\n",
    "        \n",
    "        for n in range(48, 68):\n",
    "            x = landmarks.part(n).x\n",
    "            y = landmarks.part(n).y\n",
    "            cv2.circle(frame, (x, y), 1, (0, 255, 0), -1)  # Mouth landmarks in green\n",
    "        \n",
    "        # Display the average EAR and MAR on the frame\n",
    "        cv2.putText(frame, f\"Eye EAR: {eye_ear:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Mouth MAR: {mouth_mar:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with landmarks\n",
    "    cv2.imshow('Face, Eye EAR, and Mouth MAR Detection', frame)\n",
    "\n",
    "    # Exit if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf7a097-8aaa-496d-91f2-7443ac05a49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
